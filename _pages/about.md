---
permalink: /
title: ""
author_profile: true
redirect_from: 
  - /about/
  - /about.html
---

I am a second-year M.S. student in the Department of Industrial and Systems Engineering at KAIST, advised by Prof. Hwanjun Song. I received my B.S. in Industrial Engineering from Yonsei University, where I worked as a research intern with Prof. Kyungwoo Song. I hold dual citizenship of the United States of America and the Republic of Korea, and I am planning to apply for Ph.D. programs in Fall 2026 as a domestic student in the U.S.

My research focuses on enhancing multimodal large language models (LLMs) and vision–language models (VLMs) for deeper understanding across multiple modalities, including images, text, audio, and video. I am particularly interested in advancing AI–human interaction, aiming to develop systems where AI can accurately interpret human intentions and humans can effectively guide AI’s development. I approach this goal from a multimodal perspective, seeking to bridge modalities for more natural and effective interaction.

---

## Publications

**Robust Dataset Condensation using Supervised Contrastive Learning**  
**Nicole Hee-Yeon Kim** and Hwanjun Song  
*ICCV 2025 (Accepted)*

**Towards Multi-dimensional Evaluation of LLM Summarization across Domains and Languages**  
Hyangsuk Min, Yuho Lee, Minjeong Ban, Jiaqi Deng, **Nicole Hee-Yeon Kim**, Taewon Yun, Hang Su, Jason Cai, Hwanjun Song  
*ACL 2025, Main*  
[paper](https://arxiv.org/abs/2506.00549) [code](https://github.com/DISL-Lab/MSumBench)

**IMC: A Benchmark for Invariant Learning under Multiple Causes**  
Taero Kim, Seonggyun Lee, Joonseong Kang, Youngjun Choi, Wonsang Yun, **Nicole Hee-Yeon Kim**, Ziyu Chen, Lexing Xie, Kyungwoo Song  
*CVPR 2025 Workshop on Domain Generalization: Evolution, Breakthroughs, and Future Horizons, Best Paper Award*  
[paper](https://openaccess.thecvf.com/content/CVPR2025W/DG-EBF/html/Kim_IMC_A_Benchmark_for_Invariant_Learning_under_Multiple_Causes_CVPRW_2025_paper.html) [code](https://github.com/MLAI-Yonsei/multiple_causes)

**Learning to Verify Summary Facts with Fine-Grained LLM Feedback**  
Jihwan Oh, Jeonghwan Choi, **Nicole Hee-Yeon Kim**, Taewon Yun, Hwanjun Song  
*COLING 2025, Oral*  
[paper](https://arxiv.org/abs/2412.10689) [code](https://github.com/DISL-Lab/FineSumFact)

**Robust Dataset Condensation via Semi-Supervised Learning**  
Kim, H., Choi, J., Lee, Y., Song, H.  
*KCC 2025, Oral*  
[paper](LINK_TO_PAPER) [code](LINK_TO_CODE)

**Improving Language Model Quality through LLM-based Fine-Grained Hallucinated Summary Generation**  
Oh, J., Choi, J., Kim, H., Song, H.  
*Journal of Computing Practice, vol. 31(2), pp. 91-97.*  
[paper](LINK_TO_PAPER) [code](LINK_TO_CODE)

**Robust Dataset Condensation via Supervised Contrastive Learning**  
Kim, H., Lee, Y., Song, H.  
*KSC 2024, Oral*  
[paper](LINK_TO_PAPER) [code](LINK_TO_CODE)

**Improving the Text Summary Quality Through Understanding the Hallucination Level of Summarization Using Large Language Models**  
Oh, J., Choi, J., Kim, H., Song, H.  
*KCC 2024, Oral*  
[paper](LINK_TO_PAPER) [code](LINK_TO_CODE)

---

## Honors and Awards

- **Best Paper Award**, CVPR Workshop (2023) – 학부 인턴 연구 참여
- **Full Scholarship**, KAIST Support Scholarship
- **Full Scholarship**, Yonsei University Welfare Scholarship
- **Brain Korea 21 (BK21) Scholarship**, Research Fellowship
